{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "878gpQGmyXl1",
        "colab_type": "text"
      },
      "source": [
        "# **Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Ayazhan Aman, Aidana Kabdulova \\\\\n",
        "Nazarbayev University \\\\\n",
        "Nur-Sultan, Kazakhstan \\\\\n",
        "ayazhan.aman@nu.edu.kz, aidana.kabdulova@nu.edu.kz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJkBFHRG6QZf",
        "colab_type": "text"
      },
      "source": [
        "#Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2OrJ-GkIbIA3"
      },
      "source": [
        "In this project, we deal with relation classification problem, which is one of the essential semantic processing tasks. Current methods which solves such natural language processing (NLP) problems require the high quality of the extracted features. There are several pre-existing natural language processing (NLP) systems like dependency parser and named entity recognizers (NER) or lexical databases such as WordNet which are very useful in order to get high level features. Even so, sometimes main information of the text may not depend on position in  the sentence. Thus, we exploit Attention-Based Bidirectional Long Short-Term Memory Networks(AttBLSTM) in order to obtain key semantic point of sentence. For this purpose we make experiments on SemEval-2010-task8 dataset.\n",
        "\n",
        "Relation classification problem is an important semantic processing task and based on predicting semantic relations between pairs of nominals. The relation classification task can be defined as follows: given a sentence $S$ which contains a pair of nominals $<e_1,e_2>$, the goal is to find relation between these two nominals $e_1$ and $e_2$.  In this work our task is to classify which of the following nine semantic relations holds between the nominals: Cause-Effect, Instrument-Agency, Product-Producer, ContentContainer, Entity-Origin, Entity-Destination, Component-Whole, Member-Collection, Message-Topic, or Other if it does not belongs to any of the nine annotated relations.\n",
        "\n",
        "\n",
        "For instance, ''burst'' and ''pressure'' connected in a Cause-Effect relation in the sentence:\n",
        "```\n",
        " \"The <e1>burst</e1> has been caused by water hammer <e2>pressure</e2>.\"\n",
        " Cause-Effect(e2,e1)\n",
        "```\n",
        "In this example, we obtain the relationship between the words burst and pressure by meaning of two nominals and context words. Thus, the representation and understanding of lexical and contextual meaning is the most important issues of semantic relation classification.\n",
        "\n",
        "Recently, deep learning has made significant progress in natural language processing. There are lots of the state-of-the-art methods used for relation classification such as CNN, convolutional DNN, BLSTM based approaches. Some approaches use NLP systems like dependency parsers and NER or lexical resources like WordNet.\n",
        "\n",
        "Our work proposes reproduction of a novel neural network AttBLSTM for relation classification. This model is combination of attention mechanism with Bidirectional LSTM, which can capture the most essential information from the text. Precisely speaking, this model can automatically identify the words which have crucial effect on classification. As it mentioned above, we make experiments on SemEval-2010-task8 dataset and obtain 74% of accuracy on test set and 75% of F1-score. We also use pre-trained vectors Glove.6B.100d to increase our accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMnoD5hX6T63",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEgKxaIEkj4y",
        "colab_type": "text"
      },
      "source": [
        "Experiments are conducted on SemEval-2010 Task 8 dataset (Hendrickx et al., 2009). This dataset contains 9 relationships (with two directions) and an undirected Other class. There are 10,717 annotated examples, including 8,000 sentences for training, and 2,717 for testing. We adopt the official evaluation metric to evaluate our systems, which is based on macro-averaged F1-score for the nine actual relations (excluding the Other relation) and takes the directionality into consideration.\n",
        "In order to compare with the work by Zhang and Wang (2015), we use the same word vectors proposed by Turian et al. (2010) (50-dimensional) to initialize the embedding layer. Additionally, to compare with the work by Zhang et al. (2015), we also use the 100-dimensional word vectors pretrained by Pennington et al. (2014).\n",
        " Since there is no official development dataset, we randomly select 1600 sentences (which is 20%) from training set for validation. The hyper-parameters for our model were tuned on the development set for each task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQfDGqvuzVPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWiskIy2ulZ",
        "colab_type": "code",
        "outputId": "a2319790-ef0f-4a54-daa0-9c9893fc95ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/SeoSangwoo/Attention-Based-BiLSTM-relation-extraction/tree/master/SemEval2010_task8_all_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SemEval2010_task8_all_data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipxy6uHA3Byg",
        "colab_type": "code",
        "outputId": "cca77187-9b6b-42be-c23c-1eaa2ebf60fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data  SemEval2010_task8_all_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YljTZNjyzdsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = ''\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "\n",
        "with open(\"/content/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT\") as f:\n",
        "  train_file = f.readlines()\n",
        "\n",
        "#with open(\"/content/SemEval2010_task8_all_data/SemEval2010_task8_testing/TEST_FILE.txt\") as f:\n",
        "  #test_file = f.readlines()\n",
        "\n",
        "with open(\"/content/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\") as f:\n",
        "  test_file = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWPywQIj32g1",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhDpbGvk4Le4",
        "colab_type": "text"
      },
      "source": [
        "In our dataset, we have 8000 training sentences and 2717 test sentences. After uploading our dataset SemEval-2010 Task 8, we did simple data pre-processing. Firstly, we replace these symbols \"<\", \">\" to symbols with space respectively \" <\", \"> \". Also, we delete all new lines. \n",
        "Using the **split()** and **replace()** methods we divide our train and test datasets to sentences and relations.\n",
        "\n",
        "In our data set we have following 10 relations: ['Instrument-Agency', 'Message-Topic', 'Content-Container', 'Entity-Origin', 'Product-Producer', 'Entity-Destination', 'Cause-Effect', 'Component-Whole', 'Other', 'Member-Collection']. Working with relations in this format is inconvenient. Therefore, we transform these relations into one-hot vector. \n",
        "\n",
        "We split our training dataset to train (80%) and validation (20%). After splitting in train set remained 6400 sentences, in validation 1600 sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-s8zP43z3TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(raw):\n",
        "    sentences, relations = [], []\n",
        "    to_replace = [(\"\\\"\", \"\"), (\"\\n\", \"\"), (\"<\", \" <\"), (\">\", \"> \")]\n",
        "    last_was_sentence = False\n",
        "    for line in raw:\n",
        "        sl = line.split(\"\\t\")\n",
        "        if last_was_sentence:\n",
        "            relations.append(sl[0].split(\"(\")[0].replace(\"\\n\", \"\"))\n",
        "            last_was_sentence = False\n",
        "        if sl[0].isdigit():\n",
        "            sent = sl[1]\n",
        "            for rp in to_replace:\n",
        "                sent = sent.replace(rp[0], rp[1])\n",
        "            sentences.append(sent)\n",
        "            last_was_sentence = True\n",
        "    print(\"Found {} sentences\".format(len(sentences)))\n",
        "    return sentences, relations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WmXThw20QC4",
        "colab_type": "code",
        "outputId": "202bff23-a079-494f-e103-8a029ab60cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "sentences, relations = prepare_dataset(train_file)\n",
        "sentences_test, relations_test = prepare_dataset(test_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 sentences\n",
            "Found 2717 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pWAaIVr0ZU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n, line in enumerate(relations):\n",
        "  if line=='Instrument-Agency':\n",
        "    relations[n]=0\n",
        "  elif line== 'Message-Topic':\n",
        "    relations[n]=1\n",
        "  elif line=='Content-Container':\n",
        "    relations[n]=2\n",
        "  elif line=='Entity-Origin':\n",
        "    relations[n]=3\n",
        "  elif line=='Product-Producer':\n",
        "    relations[n]=4\n",
        "  elif line=='Entity-Destination':\n",
        "    relations[n]=5\n",
        "  elif line=='Cause-Effect':\n",
        "    relations[n]=6\n",
        "  elif line=='Component-Whole':\n",
        "    relations[n]=7\n",
        "  elif line=='Other':\n",
        "    relations[n]=8\n",
        "  elif line=='Member-Collection':\n",
        "    relations[n]=9 \n",
        "\n",
        "for n, line in enumerate(relations_test):\n",
        "  if line=='Instrument-Agency':\n",
        "    relations_test[n]=0\n",
        "  elif line== 'Message-Topic':\n",
        "    relations_test[n]=1\n",
        "  elif line=='Content-Container':\n",
        "    relations_test[n]=2\n",
        "  elif line=='Entity-Origin':\n",
        "    relations_test[n]=3\n",
        "  elif line=='Product-Producer':\n",
        "    relations_test[n]=4\n",
        "  elif line=='Entity-Destination':\n",
        "    relations_test[n]=5\n",
        "  elif line=='Cause-Effect':\n",
        "    relations_test[n]=6\n",
        "  elif line=='Component-Whole':\n",
        "    relations_test[n]=7\n",
        "  elif line=='Other':\n",
        "    relations_test[n]=8\n",
        "  elif line=='Member-Collection':\n",
        "    relations_test[n]=9 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbCAwXdL0_4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "val_binary = to_categorical(relations)\n",
        "#print(val_binary)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "test_binary = to_categorical(relations_test)\n",
        "#print(test_binary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MssPX4qt1H3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 30000\n",
        "embedding_dim = 100\n",
        "max_length = 50\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vs = 30001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApD-Mt0c1T7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "tr_sent, te_sent, tr_rel, te_rel = train_test_split(sentences, val_binary, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-KQkjGE4x_M",
        "colab_type": "text"
      },
      "source": [
        "##Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RGYHxJl5GdN",
        "colab_type": "text"
      },
      "source": [
        "Tokenization is the first step in many natural language processing tasks. Tokenizing text is the process of splitting a piece of text into words, symbols, punctuation, spaces and other elements, thereby creating “tokens”. And for each tokens Tokenizer gives index. It means, if we split our sentences into words, each word has own index. But in some sentences, there are words that out of vocabulary. In that situation, we use OOV_taken (out-of-vocabulary). For all words which do not exist on vocabulary, OOV_taken gives index 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OetD0qwe5Md8",
        "colab_type": "text"
      },
      "source": [
        "##Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fMyElVx5SIs",
        "colab_type": "text"
      },
      "source": [
        "In our dataset sentences has a different length. To make it easier to work we should make all sentences one size. For this, we use padded sequences.\n",
        "Padding sequences mean adding zeros at the list to make it with the length size of the long sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaE6__kN1Yjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(tr_sent)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(tokenizer.word_index) \n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(tr_sent)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(te_sent)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(sentences_te)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTf5b3JE7XpO",
        "colab_type": "text"
      },
      "source": [
        "#Reproduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwmaB4vb5gM9",
        "colab_type": "text"
      },
      "source": [
        "##*Model*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmSFmUiG5mbM",
        "colab_type": "text"
      },
      "source": [
        "We do a reproduction of the article \"Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification\". In this paper authors use Att-BLSTM model for NLP task. This model have following five components:\n",
        "\n",
        "1.   Input layer: input sentence to this model;\n",
        "2.   Embedding layer;\n",
        "3.   LSTM layer;\n",
        "4.   Attention layer;\n",
        "5.   Output layer.\n",
        "\n",
        "![Fig 1](https://user-images.githubusercontent.com/6512394/41424160-42520358-7038-11e8-8db0-859346a1fa3a.PNG)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5DFhKn65ofm",
        "colab_type": "text"
      },
      "source": [
        "**Word embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gomgyaj5sA-",
        "colab_type": "text"
      },
      "source": [
        "Word embedding used for mapping a sentence consisting of $T$ words $S = {x_1, x_2, . . . , x_T }$ to real-valued vectors. We lookup embedding matrix $W^{wrd} \\in R^{d_w |V|}$ for each words in sentences $S$. Here, $|V|$ is vocabulary size and $d^w$ size of embedding. The matrix $W^{wrd}$ to be learned, $d^w$ hyper-parameter. Using the matrix-vector product \n",
        "$$e_i = W^{wrdv}v^i$$\n",
        "we convert a word $x_i$ into its word embedding $e_i$, where $v_i$ is a vector of size $|V|$ which has value 1 at index $e_i$ and 0 in all other positions. And after word embedding our sentence will look \n",
        "vector $embs = {e_1, e_2, . . . , e_T }$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA29k9fb5sbJ",
        "colab_type": "text"
      },
      "source": [
        "**Bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yanXW_35sen",
        "colab_type": "text"
      },
      "source": [
        "Next layer in our model is LSTM layer. The main idea is to introduce an adaptive gating mechanism, which decides the degree to which LSTM units keep the previous state and memorize the extracted features of the current data input.\n",
        "The following equations for the forward pass of an LSTM units:\n",
        "$$i_t = σ(W_{x_ix_t} + W_{hi}h_{t−1} + W_{ci}c_{t−1} + b_i) $$\n",
        "$$f_t = σ(W_{xf}x_t+W_{hf}h_{t−1}+W_{cf} c_{t−1} + b_f)$$\n",
        "$$g_t = tanh(W_{xc}x_t+W_{hc}h_{t−1}+W_{cc}c_{t−1}+b_c)$$\n",
        "$$c_t = i_tg_t + f_tc_{t−1}$$\n",
        "$$o_t = σ(W_{xo}x_t + W_{ho}h_{t−1} + W_{co}c_t + b_o)$$\n",
        "$$h_t = o_t tanh(c_t)$$\n",
        "\n",
        "**Variables:**\n",
        "\n",
        "$i_t$ - input gate\n",
        "\n",
        "$f_t$ - forget gate\n",
        "\n",
        "$o_t$ - output gate\n",
        "\n",
        "$x_i$ - the current input\n",
        "\n",
        "$h_{i−1}$ - the state that previous step generated\n",
        "\n",
        "$c_{i−1}$ - the current state of the cell\n",
        "\n",
        "$W_{xi}, W_{hi}, W_{ci}, b_i$, $W_{xf}$ , $W_{hf}$ , $W_{cf}$ , $b_f$, $W_{xo}, W_{ho}, W_{co}, b_o $- weight matrix\n",
        "\n",
        "Following picture shows how to works this equations. \n",
        "\n",
        "![LSTM](https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/1920px-Peephole_Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "In our task, it is beneficial to have access to future and past context. But, standard LSTM networks do not have access to future context. Therefore we use Bidirectional LSTM network.As also shown in figure above, the BiLSTM network contains forward and backward pass. The following equation present the output of the $i$-th word\n",
        "$$h_i = [h_i^{→} ⊕h_i^{←}]. $$\n",
        "Here, we use element-wise sum to combine the\n",
        "forward and backward pass outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWKDx9F95sjL",
        "colab_type": "text"
      },
      "source": [
        "**Attention Layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7KDzt8b5s_W",
        "colab_type": "text"
      },
      "source": [
        "In recent years, the so-called attention mechanism demonstrated success in tasks as question answering, machine translations, speech recognition. This attention layer basically learns the input sequence and averages the sequence accordingly to extract the relations between the words, which needs attention. \n",
        "\n",
        " Now we show the mathematical meaning of this layer. \n",
        "$$M = tanh(H)$$\n",
        "$$α = sof tmax(w^T M)$$\n",
        "$$r = Hα^T$$\n",
        "\n",
        "**Notation**\n",
        "\n",
        "$H ∈ R^{d^w ×T}$ - a matrix consisting of output vectors $[h_1, h_2, . . . , h_T]$ that the LSTM layer produced;\n",
        "\n",
        "$d^w$ - the dimension of the word vectors;\n",
        "\n",
        "$w$ -  trained parameter vector and\n",
        "\n",
        "We obtain final sentences representation using the formula below:\n",
        "$$h^∗ = tanh(r)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wiJAdTh5tFm",
        "colab_type": "text"
      },
      "source": [
        "##Classifying and Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF_3lmkO5tMG",
        "colab_type": "text"
      },
      "source": [
        "To predict label $yˆ$ from a discrete set of classes Y for a\n",
        "sentence S we use softmax classifier. The classifier takes $h^*$ as input:\n",
        "$$pˆ(y|S) = softmax (W^{(S)}h^∗ + b^{(S)})$$\n",
        "\n",
        "$$yˆ = argmax_y pˆ(y|S).$$\n",
        "\n",
        "For regulazation we use two types of Dropout (droput, recurrent dropout) in BiLSTM layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57L18u0V5tTH",
        "colab_type": "text"
      },
      "source": [
        "##Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKwS7Anp5tDF",
        "colab_type": "text"
      },
      "source": [
        "After loading the data and some pre-processing, we begin our experiments to select the best model and parameters. We use pre-trained vectors Glove.6B.100d to increase our accuracy. Glove is an unsupervised learning algorithm for obtaining vector representations for words. For following models we consider that our vocabulary size = 30000 and maximum number of words for each sentence is 50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCAzMqM9-IPI",
        "colab_type": "text"
      },
      "source": [
        "### First approach\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00lNFMQJ-Sj7",
        "colab_type": "text"
      },
      "source": [
        "Once all the data has been preprocessed and pre-trained vectors Glove.6B.100d has been downloaded we begin to build a model for Bidirectional LSTM networks. Various layers has been applied and trained. The best result was achieved with model consisting Embedding layer with embedding dimension = 100; one BiLSTM layer with 150 units; one Dropout layer with dropout rate = 0,5 and Dense layer with 10 units and \"Softmax\" activation function. We choose an ”RMSprop” optimizer for optimization and since we have amulti-class classification problem we use ”categorical crossentropy” as a loss function. In order to fit this model we fix 30 epochs.\n",
        " As a result we get 68% of accuracy on testing set and 67% of F1-score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znqvnuKB1bmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "embeddings_index = {};\n",
        "with open('/content/drive/My Drive/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK3ciQW_1fJb",
        "colab_type": "code",
        "outputId": "6fd5ade6-0a57-4bd1-e699-d3d0452cc996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(vs, embedding_dim, input_length=max_length, weights=[embeddings_matrix]))\n",
        "model1.add(Bidirectional(LSTM(150)))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#rmsprop= RMSprop(lr=0.01)\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history1 = model1.fit(training_padded, tr_rel, validation_data=(val_padded, te_rel), epochs=30, verbose=1)\n",
        "#print model.summary()\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/30\n",
            "6400/6400 [==============================] - 40s 6ms/sample - loss: 1.7905 - acc: 0.3766 - val_loss: 0.9903 - val_acc: 0.6456\n",
            "Epoch 2/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.9159 - acc: 0.6972 - val_loss: 0.9049 - val_acc: 0.7100\n",
            "Epoch 3/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.6064 - acc: 0.7973 - val_loss: 0.9382 - val_acc: 0.7031\n",
            "Epoch 4/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.3960 - acc: 0.8767 - val_loss: 1.1895 - val_acc: 0.7019\n",
            "Epoch 5/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.2444 - acc: 0.9273 - val_loss: 1.4635 - val_acc: 0.6844\n",
            "Epoch 6/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.1507 - acc: 0.9556 - val_loss: 1.6028 - val_acc: 0.6856\n",
            "Epoch 7/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.1077 - acc: 0.9702 - val_loss: 2.2026 - val_acc: 0.6269\n",
            "Epoch 8/30\n",
            "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.0847 - acc: 0.9777 - val_loss: 2.4021 - val_acc: 0.6488\n",
            "Epoch 9/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0641 - acc: 0.9839 - val_loss: 2.2640 - val_acc: 0.6850\n",
            "Epoch 10/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0536 - acc: 0.9852 - val_loss: 2.6838 - val_acc: 0.6800\n",
            "Epoch 11/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0439 - acc: 0.9887 - val_loss: 2.6976 - val_acc: 0.6850\n",
            "Epoch 12/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0366 - acc: 0.9919 - val_loss: 3.1870 - val_acc: 0.6700\n",
            "Epoch 13/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0401 - acc: 0.9906 - val_loss: 3.6104 - val_acc: 0.6463\n",
            "Epoch 14/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0352 - acc: 0.9909 - val_loss: 3.4353 - val_acc: 0.6656\n",
            "Epoch 15/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0264 - acc: 0.9947 - val_loss: 3.6962 - val_acc: 0.6844\n",
            "Epoch 16/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0160 - acc: 0.9961 - val_loss: 4.0646 - val_acc: 0.6538\n",
            "Epoch 17/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0266 - acc: 0.9937 - val_loss: 3.4652 - val_acc: 0.6762\n",
            "Epoch 18/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0350 - acc: 0.9948 - val_loss: 4.8819 - val_acc: 0.6375\n",
            "Epoch 19/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0246 - acc: 0.9959 - val_loss: 4.4921 - val_acc: 0.6525\n",
            "Epoch 20/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0310 - acc: 0.9945 - val_loss: 4.2689 - val_acc: 0.6744\n",
            "Epoch 21/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0331 - acc: 0.9942 - val_loss: 4.3762 - val_acc: 0.6575\n",
            "Epoch 22/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0164 - acc: 0.9967 - val_loss: 4.3995 - val_acc: 0.6581\n",
            "Epoch 23/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0318 - acc: 0.9937 - val_loss: 4.1840 - val_acc: 0.6831\n",
            "Epoch 24/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0292 - acc: 0.9947 - val_loss: 4.4428 - val_acc: 0.6556\n",
            "Epoch 25/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0155 - acc: 0.9975 - val_loss: 4.5627 - val_acc: 0.6750\n",
            "Epoch 26/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0313 - acc: 0.9956 - val_loss: 4.7446 - val_acc: 0.6675\n",
            "Epoch 27/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0116 - acc: 0.9978 - val_loss: 4.8472 - val_acc: 0.6762\n",
            "Epoch 28/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0261 - acc: 0.9967 - val_loss: 5.1439 - val_acc: 0.6525\n",
            "Epoch 29/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0337 - acc: 0.9967 - val_loss: 4.6873 - val_acc: 0.6662\n",
            "Epoch 30/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0285 - acc: 0.9972 - val_loss: 4.8765 - val_acc: 0.6556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfeeUosq2J3r",
        "colab_type": "code",
        "outputId": "bb972ddc-8353-4b19-a1d8-55e54283114e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "result1 = model1.evaluate(testing_padded,test_binary)\n",
        "print('Test accuracy:',result1[1])\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "import numpy as np\n",
        "y1_pred = model1.predict(testing_padded)\n",
        "y1_pred=np.round(y1_pred, 0)\n",
        "f1_1=f1_score(test_binary, y1_pred, average='weighted') \n",
        "print('f1_score:', f1_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2717/2717 [==============================] - 5s 2ms/sample - loss: 5.4110 - acc: 0.6430\n",
            "Test accuracy: 0.64298856\n",
            "f1_score: 0.6502470020275697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkjX77q9vzq",
        "colab_type": "code",
        "outputId": "16add904-ac2d-4840-967b-309c09b90dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "\n",
        "embedding_dim = 100\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(vs, embedding_dim, input_length=max_length, weights=[embeddings_matrix]))\n",
        "model2.add(Bidirectional(LSTM(150)))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#rmsprop= RMSprop(lr=0.01)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history2 = model2.fit(training_padded, tr_rel, validation_data=(val_padded, te_rel), epochs=30, verbose=1)\n",
        "#print model.summary()\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/30\n",
            "6400/6400 [==============================] - 39s 6ms/sample - loss: 1.7055 - acc: 0.4153 - val_loss: 1.1006 - val_acc: 0.6269\n",
            "Epoch 2/30\n",
            "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.8790 - acc: 0.7080 - val_loss: 1.0086 - val_acc: 0.6631\n",
            "Epoch 3/30\n",
            "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.5909 - acc: 0.8100 - val_loss: 0.9594 - val_acc: 0.6988\n",
            "Epoch 4/30\n",
            "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.3741 - acc: 0.8817 - val_loss: 1.2729 - val_acc: 0.7050\n",
            "Epoch 5/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.2373 - acc: 0.9258 - val_loss: 1.5120 - val_acc: 0.6762\n",
            "Epoch 6/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.1578 - acc: 0.9548 - val_loss: 1.6361 - val_acc: 0.6938\n",
            "Epoch 7/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.1141 - acc: 0.9673 - val_loss: 1.7997 - val_acc: 0.6737\n",
            "Epoch 8/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0732 - acc: 0.9794 - val_loss: 2.2373 - val_acc: 0.6844\n",
            "Epoch 9/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0526 - acc: 0.9845 - val_loss: 2.4323 - val_acc: 0.6794\n",
            "Epoch 10/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0457 - acc: 0.9875 - val_loss: 2.4534 - val_acc: 0.6794\n",
            "Epoch 11/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0343 - acc: 0.9923 - val_loss: 2.7831 - val_acc: 0.6712\n",
            "Epoch 12/30\n",
            "6400/6400 [==============================] - 39s 6ms/sample - loss: 0.0265 - acc: 0.9934 - val_loss: 3.1237 - val_acc: 0.6662\n",
            "Epoch 13/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0285 - acc: 0.9937 - val_loss: 3.3540 - val_acc: 0.6644\n",
            "Epoch 14/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0381 - acc: 0.9922 - val_loss: 3.3253 - val_acc: 0.6625\n",
            "Epoch 15/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0230 - acc: 0.9956 - val_loss: 4.1312 - val_acc: 0.6637\n",
            "Epoch 16/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0407 - acc: 0.9931 - val_loss: 3.7060 - val_acc: 0.6481\n",
            "Epoch 17/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0230 - acc: 0.9945 - val_loss: 3.9730 - val_acc: 0.6513\n",
            "Epoch 18/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0190 - acc: 0.9950 - val_loss: 4.1709 - val_acc: 0.6463\n",
            "Epoch 19/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0275 - acc: 0.9937 - val_loss: 4.3442 - val_acc: 0.6469\n",
            "Epoch 20/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0306 - acc: 0.9944 - val_loss: 4.1998 - val_acc: 0.6650\n",
            "Epoch 21/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0159 - acc: 0.9956 - val_loss: 3.9222 - val_acc: 0.6687\n",
            "Epoch 22/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0517 - acc: 0.9900 - val_loss: 4.0657 - val_acc: 0.6587\n",
            "Epoch 23/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0256 - acc: 0.9944 - val_loss: 4.5040 - val_acc: 0.6544\n",
            "Epoch 24/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0321 - acc: 0.9953 - val_loss: 4.7009 - val_acc: 0.6594\n",
            "Epoch 25/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0308 - acc: 0.9962 - val_loss: 4.9177 - val_acc: 0.6444\n",
            "Epoch 26/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0320 - acc: 0.9945 - val_loss: 5.1688 - val_acc: 0.6531\n",
            "Epoch 27/30\n",
            "6400/6400 [==============================] - 38s 6ms/sample - loss: 0.0212 - acc: 0.9967 - val_loss: 4.8921 - val_acc: 0.6506\n",
            "Epoch 28/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0160 - acc: 0.9959 - val_loss: 5.7151 - val_acc: 0.6494\n",
            "Epoch 29/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0269 - acc: 0.9967 - val_loss: 5.2269 - val_acc: 0.6456\n",
            "Epoch 30/30\n",
            "6400/6400 [==============================] - 37s 6ms/sample - loss: 0.0230 - acc: 0.9961 - val_loss: 5.1936 - val_acc: 0.6513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqiI9VKhB1qF",
        "colab_type": "code",
        "outputId": "fe80a907-e030-4b8d-c689-ca8540eb03fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "result2 = model2.evaluate(testing_padded,test_binary)\n",
        "print('Test accuracy:',result2[1])\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "import numpy as np\n",
        "y2_pred = model2.predict(testing_padded)\n",
        "y2_pred=np.round(y2_pred, 0)\n",
        "f1_2=f1_score(test_binary, y2_pred, average='weighted') \n",
        "print('f1_score:', f1_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2717/2717 [==============================] - 5s 2ms/sample - loss: 4.7678 - acc: 0.6813\n",
            "Test accuracy: 0.6812661\n",
            "f1_score: 0.678821086488234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_sMzoA7G6Cu",
        "colab_type": "text"
      },
      "source": [
        "### Second approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKvPAdjTG-Q0",
        "colab_type": "text"
      },
      "source": [
        "For the second approach we added attention mechanism to our network. After testing on different models with different parameters, we settled on a model which consists Embedding layer with embedding dimension = 100; one BiLSTM layer which has 150 units, dropout = 0.2 and reccurent_dropout = 0.2; Attention layer and Dense layer with 10 units and \"Softmax\" activation function. We again choose an ”RMSprop” optimizer for optimization and since we have a multi-class classification problem we use ”categorical crossentropy” as a loss function. In order to fit this model we fix 30 epochs. As a result we get 73% of accuracy on testing set and 73% of F1-score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxt00Un9J5OZ",
        "colab_type": "code",
        "outputId": "fca849db-0e63-4c8c-f9b4-a232fdc5ea6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "pip install keras-self-attention"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.3.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSf7v9gvJ5oB",
        "colab_type": "code",
        "outputId": "7c88f809-171d-4ab9-a15f-f03a49489df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Flatten\n",
        "\n",
        "\n",
        "model4 = models.Sequential()\n",
        "# model.add( Embedding(max_features, 32,  mask_zero=True))\n",
        "model4.add( Embedding(vs, embedding_dim, input_length=max_length, weights=[embeddings_matrix], mask_zero=True))\n",
        "model4.add(Bidirectional( LSTM(150, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
        "# add an attention layer\n",
        "\n",
        "# model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model4.add(SeqWeightedAttention())\n",
        "\n",
        "model4.add( Dense(10, activation='softmax') )\n",
        "\n",
        "# compile and fit\n",
        "model4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model4.summary()\n",
        "\n",
        "history4 = model4.fit(training_padded, tr_rel, validation_data=(val_padded, te_rel), epochs=30, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 50, 100)           3000100   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 50, 300)           301200    \n",
            "_________________________________________________________________\n",
            "seq_weighted_attention_7 (Se (None, 300)               301       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                3010      \n",
            "=================================================================\n",
            "Total params: 3,304,611\n",
            "Trainable params: 3,304,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/30\n",
            "6400/6400 [==============================] - 75s 12ms/step - loss: 1.6325 - acc: 0.4222 - val_loss: 1.2206 - val_acc: 0.5563\n",
            "Epoch 2/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 1.0426 - acc: 0.6342 - val_loss: 0.9646 - val_acc: 0.6469\n",
            "Epoch 3/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.8457 - acc: 0.7009 - val_loss: 0.9267 - val_acc: 0.6606\n",
            "Epoch 4/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 0.7346 - acc: 0.7361 - val_loss: 0.8593 - val_acc: 0.6869\n",
            "Epoch 5/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.6419 - acc: 0.7730 - val_loss: 0.8967 - val_acc: 0.6663\n",
            "Epoch 6/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.5464 - acc: 0.8011 - val_loss: 0.8310 - val_acc: 0.7137\n",
            "Epoch 7/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 0.4828 - acc: 0.8234 - val_loss: 0.8241 - val_acc: 0.7113\n",
            "Epoch 8/30\n",
            "6400/6400 [==============================] - 68s 11ms/step - loss: 0.4154 - acc: 0.8516 - val_loss: 0.8430 - val_acc: 0.7156\n",
            "Epoch 9/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.3549 - acc: 0.8728 - val_loss: 0.8737 - val_acc: 0.7231\n",
            "Epoch 10/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 0.3031 - acc: 0.8948 - val_loss: 0.8894 - val_acc: 0.7262\n",
            "Epoch 11/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 0.2565 - acc: 0.9072 - val_loss: 0.9374 - val_acc: 0.7087\n",
            "Epoch 12/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.2172 - acc: 0.9247 - val_loss: 0.9955 - val_acc: 0.7056\n",
            "Epoch 13/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.1844 - acc: 0.9330 - val_loss: 1.0598 - val_acc: 0.7050\n",
            "Epoch 14/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 0.1407 - acc: 0.9520 - val_loss: 1.0766 - val_acc: 0.7194\n",
            "Epoch 15/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.1190 - acc: 0.9611 - val_loss: 1.0977 - val_acc: 0.7156\n",
            "Epoch 16/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.1004 - acc: 0.9680 - val_loss: 1.2048 - val_acc: 0.7037\n",
            "Epoch 17/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0895 - acc: 0.9703 - val_loss: 1.2739 - val_acc: 0.6931\n",
            "Epoch 18/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0600 - acc: 0.9808 - val_loss: 1.2052 - val_acc: 0.7206\n",
            "Epoch 19/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0472 - acc: 0.9863 - val_loss: 1.3117 - val_acc: 0.7200\n",
            "Epoch 20/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0442 - acc: 0.9852 - val_loss: 1.3535 - val_acc: 0.7181\n",
            "Epoch 21/30\n",
            "6400/6400 [==============================] - 71s 11ms/step - loss: 0.0333 - acc: 0.9891 - val_loss: 1.3630 - val_acc: 0.7300\n",
            "Epoch 22/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0299 - acc: 0.9906 - val_loss: 1.3980 - val_acc: 0.7156\n",
            "Epoch 23/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0242 - acc: 0.9925 - val_loss: 1.4040 - val_acc: 0.7194\n",
            "Epoch 24/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0203 - acc: 0.9944 - val_loss: 1.5139 - val_acc: 0.7075\n",
            "Epoch 25/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0192 - acc: 0.9952 - val_loss: 1.6470 - val_acc: 0.6937\n",
            "Epoch 26/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0156 - acc: 0.9959 - val_loss: 1.5955 - val_acc: 0.7050\n",
            "Epoch 27/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0104 - acc: 0.9975 - val_loss: 1.5797 - val_acc: 0.7194\n",
            "Epoch 28/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0101 - acc: 0.9966 - val_loss: 1.6463 - val_acc: 0.7219\n",
            "Epoch 29/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 1.6948 - val_acc: 0.7181\n",
            "Epoch 30/30\n",
            "6400/6400 [==============================] - 70s 11ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 1.8771 - val_acc: 0.6931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCrL4EIksMmP",
        "colab_type": "code",
        "outputId": "cd76e09e-bc37-488f-d469-b9141ffbd0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "result4 = model4.evaluate(testing_padded,test_binary)\n",
        "print('Test accuracy:',result4[1])\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
        "import numpy as np\n",
        "y4_pred = model4.predict(testing_padded)\n",
        "y4_pred=np.round(y4_pred, 0)\n",
        "f1_4=f1_score(test_binary, y4_pred, average='weighted') \n",
        "print('f1_score:', f1_4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2717/2717 [==============================] - 10s 4ms/step\n",
            "Test accuracy: 0.7331615750035864\n",
            "f1_score: 0.7392195331114566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTL_79jJG3MM",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3DF_iVHHNE7",
        "colab_type": "text"
      },
      "source": [
        "**Results in Tabular form**\n",
        "---\n",
        "\n",
        "Our model | | Paper's model|  |\n",
        "--- | --- | --- | --- \n",
        "**Model** | **F1-score** | **Model** | **F1-score** |\n",
        "BLSTM   | 67.8% | BLSTM | 80.7%\n",
        "Att-BLSTM | 73.9% | Att-BLSTM | 82.5%\n",
        "**Table-1. F1-score of different models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdFpQY71J4OT",
        "colab_type": "text"
      },
      "source": [
        "# Colclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_LdmYVQSTtH",
        "colab_type": "text"
      },
      "source": [
        "In this project we experienced with SemEval-2010 Task 8 dataset (Hendrickx et al., 2009). We tried to reproduce \"Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification\" paper. We constructed same model but also added pre-trained vectors Glove.6B.100d since our accuracy was quite low. Although obtained F1-scores are a little bit different from paper's, from the given results in Table-1 we can conclude that model with Attention mechanism classifies better than simple BiLSTM."
      ]
    }
  ]
}